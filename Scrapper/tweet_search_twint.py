# -*- coding: utf-8 -*-
"""Tweet-search - twint

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uqHe3q_Tt_bHsh8zdOUTIYW3dyeklz6u
"""


# Import Library
import twint
import pandas 
import nest_asyncio

"""## Get tweets
Get the tweets, #cb and #sg
"""

# Instantiate and configure the twint-object
nest_asyncio.apply()
# Configuration to run the twitter web scrapping
def configuration():
    c = twint.Config()
    c.Store_object = True
    c.Pandas =True
    c.Search = ['#cb' , '#sg']
    c.Limit = 10000
    c.Since = "2020-02-01"
    c.Until = "2020-02-28"
    c.Langague = "en"
    return c

# Run search
configuration = configuration()
twint.run.Search(configuration)

# Quick check on the data frame
twint.storage.panda.Tweets_df

"""### The End (of the data extraction)
the stuff below is just some cleanup...
"""

# store the tweets as pandas dataframe
tweets = twint.storage.panda.Tweets_df.drop_duplicates(subset=['id'])

# Clean data
tweets = tweets.dropna(subset=['tweet'])

# Remove Unnecssary data
tweets = tweets.drop(columns=['id', 'conversation_id', 'translate','trans_src','trans_dest'])

# Reindex
tweets.index = range(len(tweets))

# Done
tweets.to_csv('tweets_lockdown.csv')